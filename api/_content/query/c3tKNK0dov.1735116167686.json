{"_path":"/maps/_web/crawler","_dir":"_web","_draft":false,"_partial":true,"_locale":"","title":"爬虫与反爬虫","description":"","body":{"type":"root","children":[{"type":"element","tag":"h1","props":{"id":"爬虫与反爬虫"},"children":[{"type":"text","value":"爬虫与反爬虫"}]},{"type":"element","tag":"h2","props":{"id":"技术问题"},"children":[{"type":"text","value":"技术问题"}]},{"type":"element","tag":"h4","props":{"id":"有哪些常见的反爬虫策略"},"children":[{"type":"text","value":"有哪些常见的反爬虫策略？"}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"前端主要从 HTML、CSS、JS 的角度去考虑。HTML 和 CSS 的策略较简单，比如 iframe 延迟加载、隐形内容、background 偏移、字体重映射等。JS 加密一般会用于价值较高的项目。服务器端可以分主动防御和被动防御两项，指纹、蜜罐、无头浏览器校验、UA、IP、robots.txt 等等。"}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"通过对规则进行组合可以设计出更严格的的反爬策略，如：先访问某图片才能访问某 URL，否则被计分。"}]},{"type":"element","tag":"h4","props":{"id":"js-加密如何破解"},"children":[{"type":"text","value":"JS 加密如何破解？"}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"主要依靠调试，找到加解密的关键 JS 函数。"}]},{"type":"element","tag":"h4","props":{"id":"多进程协程多线程如何选择"},"children":[{"type":"text","value":"多进程、协程、多线程如何选择？"}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"爬虫在抓取阶段时是网络密集的，解析数据阶段是 CPU 密集的，写入数据阶段是 IO 密集的。由于大部分开销都花费在了抓取阶段，所以宜选择多线程或协程的方式写爬虫程序。更好的方式可能是非阻塞 IO（异步 IO）。"}]},{"type":"element","tag":"h4","props":{"id":"增量爬取是怎么设计的"},"children":[{"type":"text","value":"增量爬取是怎么设计的？"}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"通过网址管理器管理每个 URL 的状态。它维护了如 URL 是否被下载完、下载失败次数、子页面等数据，并能根据需求返回仍未被抓取的页面 URL。"}]},{"type":"element","tag":"h4","props":{"id":"如何判断页面的相似性"},"children":[{"type":"text","value":"如何判断页面的相似性？"}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"使用 Google 的 SmithHash 算法。"}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"见："},{"type":"element","tag":"a","props":{"href":"https://www.likecs.com/show-204424165.html","rel":["nofollow"]},"children":[{"type":"text","value":"SimHash 算法原理"}]}]},{"type":"element","tag":"h4","props":{"id":"架构技巧"},"children":[{"type":"text","value":"架构技巧？"}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"爬虫分为抓取、解析和写入三个阶段，所以可以拆分为抓取写入以及读取解析两个程序，分别部署，提高应用以及维护的效率。"}]},{"type":"element","tag":"h4","props":{"id":"如何测试网站的抓取极限"},"children":[{"type":"text","value":"如何测试网站的抓取极限？"}]},{"type":"element","tag":"p","props":{},"children":[{"type":"text","value":"如果测试每分钟抓 100 次被封了，那么很可能在 80 次就上了监控，所以可以把频次控制在 40 次左右，防止别人的爬虫触发了目标站的反爬虫限制（如 80 次上监控进化为 60 次）。"}]},{"type":"element","tag":"h2","props":{"id":"调试工具"},"children":[{"type":"text","value":"调试工具"}]},{"type":"element","tag":"ul","props":{},"children":[{"type":"element","tag":"li","props":{},"children":[{"type":"element","tag":"a","props":{"href":"https://github.com/adriancooney/puppeteer-heap-snapshot","rel":["nofollow"]},"children":[{"type":"text","value":"puppeteer-heap-snapshot"}]},{"type":"text","value":"，根据属性的名字遍历堆内存，查找有这些属性的对象。"}]}]},{"type":"element","tag":"h2","props":{"id":"links"},"children":[{"type":"text","value":"Links"}]},{"type":"element","tag":"p","props":{},"children":[{"type":"element","tag":"a","props":{"href":"https://www.yuanrenxue.com/crawler/why-write-python-crawler.html","rel":["nofollow"]},"children":[{"type":"text","value":"TODO，猿人学爬虫教程"}]}]}],"toc":{"title":"","searchDepth":2,"depth":2,"links":[{"id":"技术问题","depth":2,"text":"技术问题"},{"id":"调试工具","depth":2,"text":"调试工具"},{"id":"links","depth":2,"text":"Links"}]}},"_type":"markdown","_id":"content:6.maps:_web:crawler.md","_source":"content","_file":"6.maps/_web/crawler.md","_stem":"6.maps/_web/crawler","_extension":"md"}