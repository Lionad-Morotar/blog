---
title: Datadog LLM Observability
description: 为 LLM 与 Agent 工作流提供端到端追踪、监控与诊断，融入 Datadog APM 体系；对已用 Datadog 的团队较友好，但埋点与协同要求高。
---

## Brief

Datadog LLM Observability 为大语言模型与 Agent 型应用的工作流提供端到端的追踪、监控与诊断。它将每个提示、工具调用与中间步骤映射为 spans 与 traces；跟踪时延、Token 用量、错误与质量指标；并与 Datadog 更广泛的 APM 与可观测性套件集成。

对于已在使用 Datadog、熟悉其成本结构的组织而言，只要工作负载能够被正确埋点，LLM 可观测性功能是获取 AI 工作负载可见性的直接路径。然而，LLM 埋点的配置与使用需要谨慎，且要求对工作负载及其实现有扎实理解。我们建议数据工程与运维团队在部署时密切协作。另参见我们关于避免“独立数据工程团队”的建议。

来源：技术雷达

## Details
### 背景与现状
#### 为什么现在需要 LLM 可观测性
- LLM 与 Agent 的执行链路多跳、多工具，错误与延迟来源分散，传统日志难以还原根因。
- 业务开始关注“质量/成本/延迟”的三角平衡，需要可度量、可回溯的数据来支撑优化与治理。
- 已采用 Datadog 的组织希望在既有 APM/指标/告警框架内统一治理 AI 工作负载。

### 问题与风险
#### 典型痛点与结构性矛盾
- 黑盒链路：提示模板、模型版本、工具调用与外部依赖交织，缺乏统一 Trace 视角。
- 成本不透明：高频调用与高基数标签可能放大观测成本与数据基建开销。
- 质量不可证：离线评测与线上表现常不一致，缺少面向场景的线上质量度量。
- 数据敏感性：提示/上下文可能含敏感信息，原样上报带来合规与泄露风险。
- 变更不可控：Prompt/模型/工具变更缺乏版本化与灰度策略，出现“回不去”的质量回退。

### 模式与原理
#### 端到端追踪的核心抽象
- Trace 代表一次业务请求或 Agent 任务；Span 对应关键阶段：Prompt、Tool 调用、检索、Rerank、模型推理等。
- 关键维度建议：model 与版本、prompt 模板哈希、调用角色（system/user/assistant）、工具名称、数据来源、采样率、租户/业务线、请求规模（tokens in/out）。
- 关键事件：超时、重试、截断、Rate Limit、供应商错误码、Guardrail 触发、回退策略命中。

#### 指标与质量度量
- 性能：P50/P95/P99 时延；队列等待与推理时延拆分；工具调用成功率与尾部延迟。
- 成本：输入/输出 Token、推理时长、供应商计费单位；按租户/场景聚合。
- 质量：规则型指标（拒识率/敏感命中率/格式合规率）、业务型指标（任务成功率/人工复核通过率）、系统性指标（对话步数、回退率）。
- 关联：将线上评审样本与 Trace 绑定，形成“问题案例可复现”的闭环。

#### 与 APM 的集成方式
- 传递 Trace/Span 上下文贯穿 Web/API → 编排层 → 工具/检索 → 模型调用。
- 统一告警与 SLO：以业务成功率、P99 延迟、成本预算为主指标，结合异常分布与错误比率。
- 看板与探索：按模型/版本、Prompt 哈希、工具类型、租户维度钻取，定位“谁最贵/最慢/最不稳定”。

#### 成本与数据治理
- 采样优先：对低风险流量进行采样，对错误/高延迟/高成本请求提升采样比。
- 降基数：对长文本做哈希/指纹化，只保留可检索的摘要或模板标识。
- 脱敏与最小化：敏感字段上报前脱敏/截断；仅在需要时捕获原文，并控制留存周期。

### 对比与演进
#### 从“日志拼接”到“APM 级 LLM 可观测性”
- 仅日志：低门槛但难以还原全链路，跨组件关联弱，难做 SLO。
- APM 集成：以 Trace 为主线，统一指标/日志/事件；能面向业务做聚合与告警。
- 专用 LLMOps 平台：更强评测/对齐/数据管理能力，但与现有 APM 体系割裂。对已深度使用 Datadog 的团队，优先用 APM 集成形成“可运行的最小闭环”，再按需补齐评测与数据资产能力。

### 系统性影响
#### 架构与工程效率
- 标准化编排：推动将 Prompt/检索/工具封装为可观测的“阶段组件”，提升可维护性与灰度能力。
- 质量文化：从“感觉可用”转向“可度量与可回溯”，促进问题复盘与模板治理。
- 技术栈治理：促使模型与 Prompt 版本化、灰度发布、回退策略纳入变更管理。
- 安全与合规：引入统一脱敏策略、最小化上报原则与留存策略。

#### 组织协作
- 数据工程 × 运维 × 应用团队协作上云；避免“独立数据工程团队”形成割裂，优先嵌入式协同与平台化支持。
- 角色分工：平台/运维定义可观测性标准与落地框架；应用团队按标准埋点；数据工程支持质量数据管线与评测闭环。

### 落地建议
#### 适用与边界
- 更适用：已有 Datadog 基础、AI 流量稳定增长、对质量/成本有明确 SLO 的团队。
- 谨慎或不适用：强合规场景无法脱敏上报；对成本极敏感但无法采样/降基数的业务。

#### 前置条件
- 基线规范：Trace 贯穿、必备标签（模型/版本/模板哈希/工具名/租户）、统一错误码与重试策略。
- 数据安全：脱敏白名单、敏感字段识别与拦截、留存与访问控制。
- 成本控制：采样策略、指标与日志配额、看板与预算告警。

#### 试点路径（建议三步）
1) 最小闭环：选一个关键用例，打通端到端 Trace，接入时延/错误/Token 指标与基础告警。
2) 质量落地：接入规则型质量指标与人工复核样本回流，建立问题样本库与复盘机制。
3) 扩展与治理：推广到多场景，完善版本化/灰度/回退；引入成本看板与预算 SLO。

#### 常见风险与对策
- 数据爆炸与账单上升：强制采样与降基数，聚焦关键维度与异常加样。
- 隐私泄露：默认脱敏与模板哈希，仅在受控渠道保存原文。
- 误观测与误判：将离线评测与线上指标结合，定期校验质量指标与业务目标的相关性。
- 难以推广：以平台能力与脚手架降低埋点成本，提供示例与校验工具，配合变更流程与 Code Review 守门。

总体而言，Datadog LLM Observability 能将 LLM/Agent 链路纳入现有 APM 体系，快速建立“可观测的最小闭环”。关键在于：标准化埋点、成本/安全守护、以及数据工程与运维的紧密协作。
