# 爬虫与反爬虫

[TOC]

## 技术问题

#### 有哪些常见的反爬虫策略？

前端主要从 HTML、CSS、JS 的角度去考虑。HTML 和 CSS 的策略较简单，比如 iframe 延迟加载、隐形内容、background 偏移、字体重映射等。JS 加密一般会用于价值较高的项目。服务器端可以分主动防御和被动防御两项，指纹、蜜罐、无头浏览器校验、UA、IP、robots.txt 等等。

通过对规则进行组合可以设计出更严格的的反爬策略，如：先访问某图片才能访问某 URL，否则被计分。

#### JS 加密如何破解？

主要依靠调试，找到加解密的关键 JS 函数。

#### 多进程、协程、多线程如何选择？

爬虫在抓取阶段时是网络密集的，解析数据阶段是 CPU 密集的，写入数据阶段是 IO 密集的。由于大部分开销都花费在了抓取阶段，所以宜选择多线程或协程的方式写爬虫程序。更好的方式可能是非阻塞 IO（异步 IO）。

#### 增量爬取是怎么设计的？

通过网址管理器管理每个 URL 的状态。它维护了如 URL 是否被下载完、下载失败次数、子页面等数据，并能根据需求返回仍未被抓取的页面 URL。

#### 如何判断页面的相似性？

使用 Google 的 SmithHash 算法。

见：[SimHash 算法原理](https://www.likecs.com/show-204424165.html)

#### 架构技巧？

爬虫分为抓取、解析和写入三个阶段，所以可以拆分为抓取写入以及读取解析两个程序，分别部署，提高应用以及维护的效率。

#### 如何测试网站的抓取极限？

如果测试每分钟抓 100 次被封了，那么很可能在 80 次就上了监控，所以可以把频次控制在 40 次左右，防止别人的爬虫触发了目标站的反爬虫限制（如 80 次上监控进化为 60 次）。

## 调试工具

* [puppeteer-heap-snapshot](https://github.com/adriancooney/puppeteer-heap-snapshot)，根据属性的名字遍历堆内存，查找有这些属性的对象。

## Links

[TODO，猿人学爬虫教程](https://www.yuanrenxue.com/crawler/why-write-python-crawler.html)
